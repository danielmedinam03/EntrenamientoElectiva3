{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c79dca8-a745-457b-81cb-e7774dadc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57d151e-b9c6-4070-bbb0-2d80fdd91320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'dataset-ajustado/train'  \n",
    "validation_data_dir = 'dataset-ajustado/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6b6715-6ca9-430a-ac1d-40d0727c1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_shape = 224\n",
    "height_shape = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03029fc6-1f49-4efb-9d50-8b30f520bde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21786 images belonging to 44 classes.\n",
      "Found 6225 images belonging to 44 classes.\n"
     ]
    }
   ],
   "source": [
    "# Definir el generador de imágenes para el conjunto de entrenamiento con aumentos de datos\n",
    "train_datagen = ImageDataGenerator(  \n",
    "    rotation_range=20,               # Rango de grados para rotación aleatoria\n",
    "    zoom_range=0.2,                  # Rango de zoom aleatorio\n",
    "    width_shift_range=0.1,           # Rango de desplazamiento horizontal aleatorio\n",
    "    height_shift_range=0.1,          # Rango de desplazamiento vertical aleatorio\n",
    "    horizontal_flip=True,            # Volteo horizontal aleatorio\n",
    "    vertical_flip=False,             # No se aplica volteo vertical\n",
    "    preprocessing_function=preprocess_input)  # Función de preprocesamiento\n",
    "\n",
    "# Definir el generador de imágenes para el conjunto de validación con los mismos aumentos de datos\n",
    "valid_datagen = ImageDataGenerator(    \n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# Crear un generador de lotes de imágenes para el conjunto de entrenamiento\n",
    "train_generator = train_datagen.flow_from_directory(  \n",
    "    train_data_dir,                  # Directorio que contiene las imágenes de entrenamiento\n",
    "    target_size=(width_shape, height_shape),  # Tamaño al que se redimensionarán las imágenes\n",
    "    batch_size=batch_size,           # Tamaño del lote\n",
    "    class_mode='categorical')        # Modo de clasificación para imágenes categóricas\n",
    "\n",
    "# Crear un generador de lotes de imágenes para el conjunto de validación\n",
    "validation_generator = valid_datagen.flow_from_directory(  \n",
    "    validation_data_dir,             # Directorio que contiene las imágenes de validación\n",
    "    target_size=(width_shape, height_shape),  # Tamaño al que se redimensionarán las imágenes\n",
    "    batch_size=batch_size,           # Tamaño del lote\n",
    "    class_mode='categorical')        # Modo de clasificación para imágenes categóricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8f050-95c7-4d3b-9ae2-1eec017247e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │     <span style=\"color: #00af00; text-decoration-color: #00af00\">102,764,544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">180,268</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │     \u001b[38;5;34m102,764,544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ fc2 (\u001b[38;5;33mDense\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │      \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)                  │         \u001b[38;5;34m180,268\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,440,812</span> (512.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,440,812\u001b[0m (512.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,268</span> (704.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,268\u001b[0m (704.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,260,544</span> (512.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m134,260,544\u001b[0m (512.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 92/680\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:54\u001b[0m 7s/step - accuracy: 0.0932 - loss: 4.8507"
     ]
    }
   ],
   "source": [
    "# Definir el número de muestras de entrenamiento y validación\n",
    "nb_train_samples = 21786 \n",
    "nb_validation_samples = 6225 \n",
    "num_classes = 44  # Cambia este valor según el número de clases en tu conjunto de datos\n",
    "epochs = 50  # Cambia este valor según tus necesidades\n",
    "\n",
    "# Definir la entrada de la red neuronal con el tamaño de las imágenes\n",
    "image_input = Input(shape=(width_shape, height_shape, 3))\n",
    "\n",
    "# Cargar el modelo VGG16 preentrenado con pesos ajustados desde ImageNet\n",
    "model = VGG16(input_tensor=image_input, include_top=True, weights='imagenet')\n",
    "\n",
    "# Obtener la salida de la penúltima capa densa del modelo VGG16 (fc2)\n",
    "last_layer = model.get_layer('fc2').output\n",
    "\n",
    "# Añadir una nueva capa densa al final del modelo para la clasificación multiclase con regularización L2 (Evita sobreajuste)\n",
    "out = Dense(num_classes, activation='softmax', kernel_regularizer='l2', name='output')(last_layer)\n",
    "\n",
    "# Crear un nuevo modelo personalizado que toma la entrada de la imagen y produce la salida clasificada\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "\n",
    "# Congelar todas las capas del modelo, excepto la capa densa añadida\n",
    "for layer in custom_vgg_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compilar el modelo con una función de pérdida, optimizador y métricas especificadas\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Mostrar un resumen del modelo que incluye la arquitectura y el número de parámetros\n",
    "custom_vgg_model.summary()\n",
    "\n",
    "# Entrenar el modelo utilizando generadores de datos para el conjunto de entrenamiento y validación\n",
    "model_history = custom_vgg_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,  # Número de pasos por época de entrenamiento\n",
    "    validation_steps=nb_validation_samples//batch_size)  # Número de pasos por época de validación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba98194-47fd-4212-8628-296147a9a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Nombre base del modelo\n",
    "model_name = \"model_VGG16_v\"\n",
    "\n",
    "# Extensión del archivo\n",
    "file_extension = \".keras\"\n",
    "\n",
    "# Directorio donde se guardarán los modelos\n",
    "model_directory = \"models/\"\n",
    "\n",
    "# Inicializar contador\n",
    "counter = 1\n",
    "\n",
    "# Generar el nombre completo del archivo\n",
    "file_name = model_name + file_extension\n",
    "\n",
    "ruta=model_directory + file_name\n",
    "print(ruta)\n",
    "# Verificar si el modelo ya está guardado\n",
    "while os.path.exists(model_directory + file_name):\n",
    "    \n",
    "    # Si el archivo existe, agregar un número al final del nombre del modelo\n",
    "    file_name = f\"{model_name}{counter}{file_extension}\"\n",
    "    counter += 1\n",
    "\n",
    "# Guardar el modelo con el nombre único en el directorio correcto\n",
    "custom_vgg_model.save(model_directory + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa42dc0-0421-403b-9b6f-e22a4b571ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTraining(hist, epochs, typeData):\n",
    "\n",
    "    # Seleccionar la figura y establecer el tamaño\n",
    "    # Dependiendo del tipo de datos (loss o accuracy), se elige la figura correspondiente\n",
    "    \n",
    "    if typeData==\"loss\":\n",
    "        plt.figure(1,figsize=(10,5))\n",
    "        yc=hist.history['loss']\n",
    "        xc=range(epochs)\n",
    "        plt.ylabel('Loss', fontsize=24)\n",
    "        plt.plot(xc,yc,'-r',label='Loss Training')\n",
    "    if typeData==\"accuracy\":\n",
    "        plt.figure(2,figsize=(10,5))\n",
    "        yc=hist.history['accuracy']\n",
    "        for i in range(0, len(yc)):\n",
    "            yc[i]=100*yc[i]\n",
    "        xc=range(epochs)\n",
    "        plt.ylabel('Accuracy (%)', fontsize=24)\n",
    "        plt.plot(xc,yc,'-r',label='Accuracy Training')\n",
    "    if typeData==\"val_loss\":\n",
    "        plt.figure(1,figsize=(10,5))\n",
    "        yc=hist.history['val_loss']\n",
    "        xc=range(epochs)\n",
    "        plt.ylabel('Loss', fontsize=24)\n",
    "        plt.plot(xc,yc,'--b',label='Loss Validate')\n",
    "    if typeData==\"val_accuracy\":\n",
    "        plt.figure(2,figsize=(10,5))\n",
    "        yc=hist.history['val_accuracy']\n",
    "        for i in range(0, len(yc)):\n",
    "            yc[i]=100*yc[i]\n",
    "        xc=range(epochs)\n",
    "        plt.ylabel('Accuracy (%)', fontsize=24)\n",
    "        plt.plot(xc,yc,'--b',label='Training Validate')\n",
    "        \n",
    "\n",
    "    plt.rc('xtick',labelsize=24)\n",
    "    plt.rc('ytick',labelsize=24)\n",
    "    plt.rc('legend', fontsize=18) \n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of Epochs',fontsize=24)\n",
    "    plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a9a72-77d1-4cb4-8cb8-5fe634fa7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTraining(model_history,epochs,\"loss\")\n",
    "plotTraining(model_history,epochs,\"accuracy\")\n",
    "plotTraining(model_history,epochs,\"val_loss\")\n",
    "plotTraining(model_history,epochs,\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a26f5-c648-421d-afe9-27ad37367358",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = r\"dataset-ajustado\\train\"\n",
    "\n",
    "# Obteniendo los nombres de las carpetas y almacenándolos en una lista\n",
    "names = [nombre for nombre in os.listdir(ruta) if os.path.isdir(os.path.join(ruta, nombre))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e400c6-8933-499b-b0e3-0deb16cec349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la imagen\n",
    "imaget_path = r\"dataset-ajustado\\test\\buho cafe\\fillbgnobg_resize_Buho Cafe-218.png\"\n",
    "\n",
    "# Leer la imagen con OpenCV - la imagen es de buho cafe \n",
    "imagen = cv2.imread(ruta_imagen)\n",
    "\n",
    "# Convertir de BGR a RGB para mostrarla correctamente con matplotlib\n",
    "imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Mostrar la imagen con matplotlib\n",
    "plt.imshow(imagen_rgb)\n",
    "plt.axis('off')  # Ocultar ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52836a92-00ab-4163-b525-58b7feb1a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# Cargar el modelo\n",
    "modelt = load_model('models/optimizado.keras')\n",
    "#modelt = custom_vgg_model\n",
    "\n",
    "# Ruta de la imagen de prueba\n",
    "#imaget_path = \"ImagenPrueba_sin_fondo.jpg\"\n",
    "\n",
    "# Leer la imagen, cambiar tamaño y preprocesar\n",
    "imaget=cv2.resize(cv2.imread(imaget_path), (width_shape, height_shape), interpolation = cv2.INTER_AREA)\n",
    "xt = np.asarray(imaget)\n",
    "xt=preprocess_input(xt)\n",
    "xt = np.expand_dims(xt,axis=0)\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "preds = modelt.predict(xt)\n",
    "\n",
    "# Obtener la clase predicha y su porcentaje de confianza\n",
    "predicted_class_index = np.argmax(preds)\n",
    "predicted_class_name = names[predicted_class_index]\n",
    "confidence_percentage = preds[0][predicted_class_index] * 100\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f'Clase predicha: {predicted_class_name}')\n",
    "print(f'Porcentaje de confianza: {confidence_percentage:.2f}%')\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(cv2.cvtColor(np.asarray(imaget), cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4afb1-ab54-4f0f-bc51-4403d71fa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test_data_dir = 'dataset/test'  \n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(width_shape, height_shape), \n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=False)\n",
    "\n",
    "custom_Model= load_model(model_directory + file_name)\n",
    "\n",
    "predictions = custom_Model.predict(test_generator)\n",
    "\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_real = test_generator.classes\n",
    "\n",
    "\n",
    "matc=confusion_matrix(y_real, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_real,y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5034d-75a4-4453-bec8-986bf0167733",
   "metadata": {},
   "source": [
    "# todos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754076b-6e3f-4ee9-adb9-fdfe43abc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Definir el número de muestras de entrenamiento y validación\n",
    "nb_train_samples = 2621\n",
    "nb_validation_samples = 738\n",
    "\n",
    "# Definir el número de épocas\n",
    "epochs = 50\n",
    "\n",
    "# Definir el tamaño de las imágenes\n",
    "width_shape = 224\n",
    "height_shape = 224\n",
    "\n",
    "# Definir el número de clases\n",
    "num_classes = 18  # Ajustar según el número de clases en tu dataset\n",
    "\n",
    "# Directorios de datos de entrenamiento y validación\n",
    "train_data_dir = 'datasetpreprocesado/train'  \n",
    "validation_data_dir = 'datasetpreprocesado/valid'\n",
    "\n",
    "# Función para crear y entrenar el modelo\n",
    "def create_and_train_vgg16_model(learning_rate, l2_regularization, batch_size):\n",
    "    # Crear generadores de datos con el batch_size proporcionado\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(width_shape, height_shape),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = valid_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(width_shape, height_shape),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Definir la entrada de la red neuronal con el tamaño de las imágenes\n",
    "    image_input = Input(shape=(width_shape, height_shape, 3))\n",
    "\n",
    "    # Cargar el modelo VGG16 preentrenado con pesos ajustados desde ImageNet\n",
    "    model = VGG16(input_tensor=image_input, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Aplanar la salida del VGG16\n",
    "    x = Flatten()(model.output)\n",
    "\n",
    "    # Añadir una nueva capa densa al final del modelo para la clasificación multiclase con regularización L2\n",
    "    out = Dense(num_classes, activation='softmax', kernel_regularizer='l2')(x)\n",
    "\n",
    "    # Crear un nuevo modelo personalizado que toma la entrada de la imagen y produce la salida clasificada\n",
    "    custom_vgg_model = Model(inputs=model.input, outputs=out)\n",
    "\n",
    "    # Congelar todas las capas del modelo base VGG16\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compilar el modelo con una función de pérdida, optimizador y métricas especificadas\n",
    "    custom_vgg_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "    # Mostrar un resumen del modelo que incluye la arquitectura y el número de parámetros\n",
    "    custom_vgg_model.summary()\n",
    "\n",
    "    # Medir el tiempo y el uso de CPU/memoria antes de entrenar\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    start_memory = psutil.virtual_memory().used\n",
    "\n",
    "    # Crear los callbacks para Early Stopping y guardar el mejor modelo\n",
    "    checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    # Entrenar el modelo utilizando generadores de datos para el conjunto de entrenamiento y validación\n",
    "    model_history = custom_vgg_model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=[checkpoint, early_stopping]\n",
    "    )\n",
    "\n",
    "    # Medir el tiempo y el uso de CPU/memoria después de entrenar\n",
    "    end_time = time.time()\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_memory = psutil.virtual_memory().used\n",
    "\n",
    "    # Calcular métricas de tiempo y uso de recursos\n",
    "    elapsed_time = end_time - start_time\n",
    "    cpu_usage = end_cpu - start_cpu\n",
    "    memory_usage = end_memory - start_memory\n",
    "\n",
    "    print(f\"Tiempo transcurrido para el entrenamiento: {elapsed_time} segundos\")\n",
    "    print(f\"Uso de CPU durante el entrenamiento: {cpu_usage}%\")\n",
    "    print(f\"Aumento en uso de memoria: {memory_usage / (1024 ** 3)} GB\")\n",
    "\n",
    "    return model_history, elapsed_time, cpu_usage, memory_usage\n",
    "\n",
    "# Definir rangos de búsqueda para hiperparámetros\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "l2_regularizations = [0.01, 0.05, 0.1]\n",
    "batch_sizes = [16, 32, 64]\n",
    "\n",
    "# Variables para almacenar los mejores hiperparámetros y su rendimiento\n",
    "best_val_accuracy = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula\n",
    "for learning_rate in learning_rates:\n",
    "    for l2_regularization in l2_regularizations:\n",
    "        for batch_size in batch_sizes:\n",
    "            # Crear y entrenar el modelo con los hiperparámetros actuales\n",
    "            model_history, elapsed_time, cpu_usage, memory_usage = create_and_train_vgg16_model(learning_rate, l2_regularization, batch_size)\n",
    "            \n",
    "            # Obtener la mejor precisión de validación de esta combinación de hiperparámetros\n",
    "            val_accuracy = np.max(model_history.history['val_accuracy'])\n",
    "            \n",
    "            # Imprimir los resultados\n",
    "            print(f\"Resultados para lr={learning_rate}, l2={l2_regularization}, batch_size={batch_size}:\")\n",
    "            print(f\"Tiempo: {elapsed_time} segundos, CPU: {cpu_usage}%, Memoria: {memory_usage / (1024 ** 3)} GB\")\n",
    "            print(f\"Precisión de validación: {val_accuracy}\")\n",
    "            \n",
    "            # Actualizar los mejores hiperparámetros si la precisión de validación mejora\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_hyperparams = {\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'l2_regularization': l2_regularization,\n",
    "                    'batch_size': batch_size,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'elapsed_time': elapsed_time,\n",
    "                    'cpu_usage': cpu_usage,\n",
    "                    'memory_usage': memory_usage\n",
    "                }\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y su rendimiento\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_hyperparams)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
